{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUKdY_MTQXYs",
        "outputId": "1ed815af-9433-4a38-8034-f6dea802a28e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.1+cu121)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision opencv-python matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "cwdMAwCyQqmX",
        "outputId": "e83f35de-d8ac-4237-dea3-4e75ba485821"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6545d6fb-15c3-4fa2-8e78-af6ac59ea43d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6545d6fb-15c3-4fa2-8e78-af6ac59ea43d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 2017-bestposter-justiceleague.jpg to 2017-bestposter-justiceleague.jpg\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded=files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9ivXjlrhQq7C"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "a0aqIYxKSBj4"
      },
      "outputs": [],
      "source": [
        "import torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7u4z51FNSBu3"
      },
      "outputs": [],
      "source": [
        "from torchvision.models.detection import maskrcnn_resnet50_fpn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sgHiFPOfSBzY"
      },
      "outputs": [],
      "source": [
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NwPDTErcSB5Y"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "-NAecY0TSbmb"
      },
      "outputs": [],
      "source": [
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "3WWrQJ2wSbqa"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "uoyULUMFSbtL"
      },
      "outputs": [],
      "source": [
        "#Load pre-trained Mask R-CNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lawfnyF9TPDx",
        "outputId": "bbaa7fa1-4a58-4884-ccc7-2de5bc1c9aad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MaskRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=MaskRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\" to /root/.cache/torch/hub/checkpoints/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\n",
            "100%|██████████| 170M/170M [00:02<00:00, 76.6MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MaskRCNN(\n",
              "  (transform): GeneralizedRCNNTransform(\n",
              "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
              "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
              "  )\n",
              "  (backbone): BackboneWithFPN(\n",
              "    (body): IntermediateLayerGetter(\n",
              "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "      (layer1): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer2): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer3): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (4): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (5): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer4): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (fpn): FeaturePyramidNetwork(\n",
              "      (inner_blocks): ModuleList(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (2): Conv2dNormActivation(\n",
              "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (layer_blocks): ModuleList(\n",
              "        (0-3): 4 x Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (extra_blocks): LastLevelMaxPool()\n",
              "    )\n",
              "  )\n",
              "  (rpn): RegionProposalNetwork(\n",
              "    (anchor_generator): AnchorGenerator()\n",
              "    (head): RPNHead(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "  )\n",
              "  (roi_heads): RoIHeads(\n",
              "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
              "    (box_head): TwoMLPHead(\n",
              "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
              "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "    )\n",
              "    (box_predictor): FastRCNNPredictor(\n",
              "      (cls_score): Linear(in_features=1024, out_features=91, bias=True)\n",
              "      (bbox_pred): Linear(in_features=1024, out_features=364, bias=True)\n",
              "    )\n",
              "    (mask_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(14, 14), sampling_ratio=2)\n",
              "    (mask_head): MaskRCNNHeads(\n",
              "      (0): Conv2dNormActivation(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "      (1): Conv2dNormActivation(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Conv2dNormActivation(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Conv2dNormActivation(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (mask_predictor): MaskRCNNPredictor(\n",
              "      (conv5_mask): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (mask_fcn_logits): Conv2d(256, 91, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "model=maskrcnn_resnet50_fpn(pretrained=True)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Ds93_l16TPKI"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Function to load image from uploaded files\n",
        "def load_image(file_dict):\n",
        "  image=None\n",
        "  for fname in file_dict.keys():\n",
        "    image=Image.open(fname).convert(\"RGB\")\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "boyjUgM_TPNg"
      },
      "outputs": [],
      "source": [
        "# Load image\n",
        "image = load_image(uploaded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "kJ6YdYJSQq-2"
      },
      "outputs": [],
      "source": [
        "# Transform the image for the model\n",
        "transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "])\n",
        "image_tensor = transform(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "PSH7wI_aT5if"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Run the model on the image\n",
        "with torch.no_grad():\n",
        "    predictions = model([image_tensor])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "s4CsoSOpT5ln"
      },
      "outputs": [],
      "source": [
        "# Get the masks and labels\n",
        "masks = predictions[0]['masks']\n",
        "labels = predictions[0]['labels']\n",
        "scores = predictions[0]['scores']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "pM7RrSVWT5pI"
      },
      "outputs": [],
      "source": [
        "# Visualize the segmentation\n",
        "image_np = np.array(image)\n",
        "for i in range(len(masks)):\n",
        "    if scores[i] > 0.5:  # Only visualize confident predictions\n",
        "        mask = masks[i, 0].numpy()\n",
        "        label = labels[i].item()\n",
        "        image_np[mask > 0.5] = (255, 0, 0)  # Highlight segmented area with red color\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "APhPIBKaQrDC",
        "outputId": "a99d51b6-0f80-48fd-f6e4-9f57e32e6797"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.imshow(image_np)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMCXewZ4QrHB",
        "outputId": "03d21349-344a-47d8-a368-9720db48a4f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.1+cu121)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement sqlite3 (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for sqlite3\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision opencv-python matplotlib sqlite3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "cx3N_SAqU7tL"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNbeumh8U7xB",
        "outputId": "5a13fe0b-8c22-4f61-df19-cd32be735a19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.1+cu121)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision opencv-python matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "-ENN6PklU70q"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "17HwbynfU73p"
      },
      "outputs": [],
      "source": [
        "import sqlite3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "maEBSEdnU77J"
      },
      "outputs": [],
      "source": [
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "rHdMWVcaU7-I"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "q4AeaJoeU8B6"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "zYtMfVjKU8GP"
      },
      "outputs": [],
      "source": [
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "ow5nnRWTU8NO"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Create directories for saving extracted objects and database\n",
        "os.makedirs('extracted_objects', exist_ok=True)\n",
        "os.makedirs('database', exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "wXllZ6I3U8Qv"
      },
      "outputs": [],
      "source": [
        "# Connect to SQLite database (or create it)\n",
        "conn = sqlite3.connect('database/segmented_objects.db')\n",
        "cursor = conn.cursor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtGYpmgoU8Yf",
        "outputId": "f7f675a6-9734-45b0-9bc0-938ebd217bf5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sqlite3.Cursor at 0x7f1e5bd7b8c0>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "# Create table for storing metadata\n",
        "cursor.execute('''\n",
        "CREATE TABLE IF NOT EXISTS objects (\n",
        "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    master_id TEXT,\n",
        "    object_id TEXT,\n",
        "    image_path TEXT\n",
        ")\n",
        "''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "4IPOcCXLWGVg"
      },
      "outputs": [],
      "source": [
        "# Function to save image with metadata\n",
        "def save_object_image(image, master_id, object_id):\n",
        "    image_path = f'extracted_objects/{object_id}.png'\n",
        "    image.save(image_path)\n",
        "\n",
        "    # Insert metadata into database\n",
        "    cursor.execute('''\n",
        "    INSERT INTO objects (master_id, object_id, image_path)\n",
        "    VALUES (?, ?, ?)\n",
        "    ''', (master_id, object_id, image_path))\n",
        "\n",
        "    conn.commit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "m-w_X7DeWKFa"
      },
      "outputs": [],
      "source": [
        "# Function to load image from uploaded files\n",
        "def load_image(file_dict):\n",
        "    image = None\n",
        "    for fname in file_dict.keys():\n",
        "        image = Image.open(fname).convert(\"RGB\")\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "xErVcW9zWPJZ",
        "outputId": "c9fc2d2b-ca43-4a62-fc1f-7fe274b0717d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-77219028-fa10-4b19-a613-abf0bdb87abb\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-77219028-fa10-4b19-a613-abf0bdb87abb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 2017-bestposter-justiceleague.jpg to 2017-bestposter-justiceleague (1).jpg\n"
          ]
        }
      ],
      "source": [
        "# Upload image\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "8eck6zHbWQP8"
      },
      "outputs": [],
      "source": [
        "# Load image\n",
        "image = load_image(uploaded)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "dCVhcFI7WQS6"
      },
      "outputs": [],
      "source": [
        "# Transform the image for the model\n",
        "transform = T.Compose([\n",
        "    T.ToTensor(),\n",
        "])\n",
        "image_tensor = transform(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "dJwBfSFzWQVy"
      },
      "outputs": [],
      "source": [
        "# Run the model on the image\n",
        "with torch.no_grad():\n",
        "    predictions = model([image_tensor])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "8z0f_s84WQY1"
      },
      "outputs": [],
      "source": [
        "# Get the masks and labels\n",
        "masks = predictions[0]['masks']\n",
        "scores = predictions[0]['scores']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "zqDkRob_WQbe"
      },
      "outputs": [],
      "source": [
        "# Generate unique master ID for the original image\n",
        "master_id = 'master_' + str(np.random.randint(10000))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "t1NiUy5FWQeI"
      },
      "outputs": [],
      "source": [
        "# Extract and save objects\n",
        "for i in range(len(masks)):\n",
        "    if scores[i] > 0.5:  # Only save confident predictions\n",
        "        mask = masks[i, 0].numpy()\n",
        "        obj_image = Image.fromarray((mask * 255).astype(np.uint8))\n",
        "        obj_image = Image.composite(image, Image.new(\"RGB\", image.size), obj_image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "cpnsk2VaWQhD"
      },
      "outputs": [],
      "source": [
        " # Generate unique object ID\n",
        "object_id = master_id + '_obj_' + str(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "gbLqNyHtWQjy"
      },
      "outputs": [],
      "source": [
        "# Save object image and metadata\n",
        "save_object_image(obj_image, master_id, object_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "Fpc8x0QBWQmr"
      },
      "outputs": [],
      "source": [
        "# Close the database connection\n",
        "conn.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rwDpPfwWQqY",
        "outputId": "0f7eef01-8934-4667-b1d0-c11663d65328"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Object extraction and storage completed successfully.\n"
          ]
        }
      ],
      "source": [
        "print(\"Object extraction and storage completed successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tjG3rLsWQu8",
        "outputId": "cd030866-68b7-48b3-84df-47f485ab9051"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.1+cu121)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision opencv-python matplotlib transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "6Mlp6011YQJX"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "Zn2HzCHEYQMT"
      },
      "outputs": [],
      "source": [
        "import sqlite3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "Zu6uwjM3YQPy"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMY-xVVAYQbO",
        "outputId": "b2d14d52-2b0b-4001-b703-52bbfe2518fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-5zmmk0j0\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-5zmmk0j0\n",
            "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.1+cu121)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Collecting ftfy (from clip==1.0)\n",
            "  Downloading ftfy-6.2.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy->clip==1.0) (0.2.13)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Downloading ftfy-6.2.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: clip\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369492 sha256=a63ac5bc1daea15298029fb413912acb19f292fa4e50fb0a940724ad41cd0ceb\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-q0q61g8b/wheels/da/2b/4c/d6691fa9597aac8bb85d2ac13b112deb897d5b50f5ad9a37e4\n",
            "Successfully built clip\n",
            "Installing collected packages: ftfy, clip\n",
            "Successfully installed clip-1.0 ftfy-6.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision opencv-python matplotlib transformers git+https://github.com/openai/CLIP.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "_O2mWHSHYQdn"
      },
      "outputs": [],
      "source": [
        "import clip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "Asx_m3qZYQge"
      },
      "outputs": [],
      "source": [
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "GzgKF27YYQj2"
      },
      "outputs": [],
      "source": [
        "from transformers import CLIPProcessor,CLIPModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "ho3-F5t3YQmT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYjfaSE-ZD1e",
        "outputId": "2e9e60a8-1530-4d1c-aead-109e15934eb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|████████████████████████████████████████| 338M/338M [00:02<00:00, 119MiB/s]\n"
          ]
        }
      ],
      "source": [
        "# Load CLIP model and processor\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model, preprocess = clip.load(\"ViT-B/32\", device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "45c7WDdQZD8V"
      },
      "outputs": [],
      "source": [
        "# Connect to SQLite database\n",
        "conn = sqlite3.connect('database/segmented_objects.db')\n",
        "cursor = conn.cursor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "wqv2gyBkZD_V"
      },
      "outputs": [],
      "source": [
        "# Fetch object images and metadata from the database\n",
        "cursor.execute(\"SELECT object_id, image_path FROM objects\")\n",
        "rows = cursor.fetchall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "3w3S_MM2ZECP"
      },
      "outputs": [],
      "source": [
        "descriptions = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "p1ndtLtEZEFG"
      },
      "outputs": [],
      "source": [
        "for row in rows:\n",
        "    object_id, image_path = row\n",
        "    image = preprocess(Image.open(image_path)).unsqueeze(0).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "LZkzsbTkZEH5"
      },
      "outputs": [],
      "source": [
        "   # Define the set of possible text descriptions\n",
        "text_descriptions = [\"a person\", \"a car\", \"a chair\", \"a desk\", \"a computer\", \"a phone\", \"a book\",\n",
        "        \"a cup\", \"a bag\", \"a bottle\", \"a keyboard\", \"a mouse\", \"a plant\"]\n",
        "text_inputs = clip.tokenize(text_descriptions).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "iTnmppQTZX1W"
      },
      "outputs": [],
      "source": [
        " # Generate features\n",
        "with torch.no_grad():\n",
        "  image_features = model.encode_image(image)\n",
        "  text_features = model.encode_text(text_inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "b-C6al5GZX4z"
      },
      "outputs": [],
      "source": [
        " # Calculate similarity\n",
        " image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "text_features /= text_features.norm(dim=-1, keepdim=True)\n",
        "similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "sfYmob2FZX8a"
      },
      "outputs": [],
      "source": [
        "# Find the most similar text description\n",
        "values, indices = similarity[0].topk(1)\n",
        "description = text_descriptions[indices.item()]\n",
        "descriptions.append({\"object_id\": object_id, \"description\": description})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "sUkm3oT1ZX_U"
      },
      "outputs": [],
      "source": [
        "# Save descriptions to a CSV file\n",
        "descriptions_df = pd.DataFrame(descriptions)\n",
        "descriptions_df.to_csv('object_descriptions.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "6YvME8FeaQlk"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Close the database connection\n",
        "conn.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qW_PHwN3aQod",
        "outputId": "2c4524dc-999c-4c6a-921a-da196ae24af0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Object identification and description completed successfully.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"Object identification and description completed successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIppQLIIaQr9",
        "outputId": "85294955-dda0-4b6f-ab5a-4a97d5c3fbc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting easyocr\n",
            "  Downloading easyocr-1.7.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.18.1+cu121)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from easyocr) (4.10.0.84)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.13.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from easyocr) (9.4.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.23.2)\n",
            "Collecting python-bidi (from easyocr)\n",
            "  Downloading python_bidi-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from easyocr) (6.0.1)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.0.5)\n",
            "Collecting pyclipper (from easyocr)\n",
            "  Downloading pyclipper-1.3.0.post5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting ninja (from easyocr)\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->easyocr) (12.6.20)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2.34.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2024.7.24)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (24.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->easyocr) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->easyocr) (1.3.0)\n",
            "Downloading easyocr-1.7.1-py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyclipper-1.3.0.post5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (908 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m908.3/908.3 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_bidi-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.3/281.3 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-bidi, pyclipper, ninja, easyocr\n",
            "Successfully installed easyocr-1.7.1 ninja-1.11.1.1 pyclipper-1.3.0.post5 python-bidi-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install easyocr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "x0n5YiuCaQvX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sqlite3\n",
        "import easyocr\n",
        "from PIL import Image\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8KN7wx2aQyo",
        "outputId": "8d0f489f-7412-4e13-fc7e-3dcdf91602c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
            "WARNING:easyocr.easyocr:Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: |██████████████████████████████████████████████████| 100.0% Complete"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: |██████████████████████████████████████████████████| 100.0% Complete"
          ]
        }
      ],
      "source": [
        "# Initialize EasyOCR reader\n",
        "reader = easyocr.Reader(['en'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "HFuoIjn5aQ1h"
      },
      "outputs": [],
      "source": [
        "# Connect to SQLite database\n",
        "conn = sqlite3.connect('database/segmented_objects.db')\n",
        "cursor = conn.cursor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "MQgIuhrYaQ4F"
      },
      "outputs": [],
      "source": [
        "# Fetch object images and metadata from the database\n",
        "cursor.execute(\"SELECT object_id, image_path FROM objects\")\n",
        "rows = cursor.fetchall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "5m1WNU6QaQ7h"
      },
      "outputs": [],
      "source": [
        "text_data = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "WO7ATcxaYQsP"
      },
      "outputs": [],
      "source": [
        "for row in rows:\n",
        "    object_id, image_path = row\n",
        "    image = Image.open(image_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "w4etL3-pYQvI"
      },
      "outputs": [],
      "source": [
        "# Perform OCR to extract text\n",
        "result = reader.readtext(image_path)\n",
        "extracted_text = \" \".join([res[1] for res in result])\n",
        "\n",
        "text_data.append({\"object_id\": object_id, \"extracted_text\": extracted_text})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "dQsVcVkpb10f"
      },
      "outputs": [],
      "source": [
        "# Save extracted text to a CSV file\n",
        "text_data_df = pd.DataFrame(text_data)\n",
        "text_data_df.to_csv('extracted_text_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "mpq1a6iSb131"
      },
      "outputs": [],
      "source": [
        "# Close the database connection\n",
        "conn.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ruFN4dMb16q",
        "outputId": "f23bc7a6-668f-48f4-d1b2-c2c52595db55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text extraction and storage completed successfully.\n"
          ]
        }
      ],
      "source": [
        "print(\"Text extraction and storage completed successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjSUxvCMcrP8",
        "outputId": "7264dc1b-864d-443b-fbb7-5d0aadd0c0a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "IVf0blt0crS4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "_-WIVyadcrY2"
      },
      "outputs": [],
      "source": [
        "# Load extracted text data\n",
        "text_data_df = pd.read_csv('extracted_text_data.csv')\n",
        "descriptions_df = pd.read_csv('object_descriptions.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "ywArvI_4crbz"
      },
      "outputs": [],
      "source": [
        "# Merge descriptions with extracted text data\n",
        "data_df = pd.merge(descriptions_df, text_data_df, on=\"object_id\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336,
          "referenced_widgets": [
            "40306821b3414eee8bfb950b03c2d6ce",
            "02fc0812dd4e4b1fa4d977b76079c97c",
            "1b5d787727f54f92ade54bc0f7c5a279",
            "3716eac980884ce1b64ceec691da2079",
            "bd7888ce12a84b23ab443cd9918e7ae5",
            "962e5f68759f46f087aefe7c7d60a2c0",
            "b90940076bc246a2bb7aff1ef51daac2",
            "c266010897b546a79a36c621723bcd06",
            "22d84ffd7ebf49f0917facc980597701",
            "a5e3a0f34ed8444ea6090f8edc4db27c",
            "d746c3cb6f3a4bec8fdf2c5cc23e867f",
            "4b59d32a6d944b529185cbc5c23ea04d",
            "f3c2941dff174eb686f036d54c89439f",
            "6e6620330e4642b68865dce0e9d874a8",
            "56ecc7a239d64f1aa3dc4dceb52be534",
            "9e4a1a1b795c43018910cf201f80c3f3",
            "ed8e66fa611f4c16b794bcdb8c32cdca",
            "bbbb1c78f1014c28b137eaff8f4befa8",
            "4e45957ddd574bdd80cb7566361e4b67",
            "1650945944734f7cbccd76794101ca76",
            "506906f469404aecb938de914a078bc9",
            "cbec80d1d097437184022d5051cb751c",
            "595e933dc6b04b05ab3e77cfde2f2595",
            "486444665624443b9f04778a3b450aa0",
            "a5b36dd8326e46b89f0ba101cdc6d201",
            "8fc30719b070432e8733de0f027feec6",
            "bf30c92a572a4a049985f57663db3406",
            "e94353f5e1ca4e82ab56f6e72f963e6d",
            "96db8f5cb9124857902d490353ecd72e",
            "be3562e80cdd45d9bb99ebd9de637c31",
            "07e91e791af74b68b113e9ec90ad5b02",
            "95d96240bf044a7b9d93bbd8d57f27fd",
            "4dbeb5c8f9c34237983aa10cd8c28488",
            "a176519cc891486f8bc57002e1cdbba0",
            "6381bafb1179423fadc755a409bdb34c",
            "879bb8035884482a942866c90d58d150",
            "51db171daf3f434bb1da11324d5a7f93",
            "18aa878ef256402daaf4f35bf25e849e",
            "d7dc5cd7a8d14596b2407292bf4b131b",
            "89ef9d0c34ed4e00a9cd7ea02be14243",
            "0123f24b86d24941a061aa0f299e750a",
            "79f24422b0c841eabe60611d84dd1112",
            "4cb7f1d7274642268a94fd0b799f935e",
            "50d04fdb8d5c4e23aa6e64d43c175423",
            "1017c5f275754070b7cb91491c9d30e7",
            "01e62dd02ea24019a5a59fbce06f5c5e",
            "8c5e3e77484b48f580950e2d07921db4",
            "6de8565f0a054414847fb03e55d8906f",
            "d1a2059c4a714d2daa4eee49504accac",
            "ec85e00e920a4211ab1cf31bfcf738e1",
            "9adedadc98b04694a2e6a7c8349cae1f",
            "2e34f2a5923f4cb78a5d92e258033582",
            "56acb744ee6640af80fb13f0d682e113",
            "599cdde41af74cfdb4cef4eb483a6daf",
            "8702b18e9a214257b6eb233e470326c7"
          ]
        },
        "id": "KGnml-BScrei",
        "outputId": "2d80f523-72c8-4ee1-a6a5-9a03a0384d8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.80k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "40306821b3414eee8bfb950b03c2d6ce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b59d32a6d944b529185cbc5c23ea04d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "595e933dc6b04b05ab3e77cfde2f2595"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a176519cc891486f8bc57002e1cdbba0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1017c5f275754070b7cb91491c9d30e7"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Initialize summarization pipeline\n",
        "summarizer = pipeline(\"summarization\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "j3XlZB3ycrg5"
      },
      "outputs": [],
      "source": [
        "summaries = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "qnf7ZN4Ycrm9"
      },
      "outputs": [],
      "source": [
        "for index, row in data_df.iterrows():\n",
        "    object_id = row['object_id']\n",
        "    description = row['description']\n",
        "    extracted_text = row['extracted_text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "lvSjW90FcrqN"
      },
      "outputs": [],
      "source": [
        " # Combine description and extracted text\n",
        "combined_text = f\"Description: {description}. Extracted text: {extracted_text}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wh4Zi8UXcrtD",
        "outputId": "bf90f090-df0b-46d0-b4da-a597325666a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 50, but your input_length is only 12. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=6)\n"
          ]
        }
      ],
      "source": [
        " # Generate summary\n",
        "summary = summarizer(combined_text, max_length=50, min_length=25, do_sample=False)[0]['summary_text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "AHvEJHZWdXdQ"
      },
      "outputs": [],
      "source": [
        "summaries.append({\"object_id\": object_id, \"summary\": summary})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "oyCJshKbdeD_"
      },
      "outputs": [],
      "source": [
        "# Save summaries to a CSV file\n",
        "summaries_df = pd.DataFrame(summaries)\n",
        "summaries_df.to_csv('object_summaries.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKkkcYOldhCM",
        "outputId": "c0d1d1a5-92ff-4bbe-fe4c-372ceb8d87c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarization of object attributes completed successfully.\n"
          ]
        }
      ],
      "source": [
        "print(\"Summarization of object attributes completed successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "DIBYoo0BdlKs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "wcqNRG-DiFhG"
      },
      "outputs": [],
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "import json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqHdlF6yiFnU",
        "outputId": "cb61016d-47d9-4482-c5f0-d066cac15f30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tables in the database:               name\n",
            "0          objects\n",
            "1  sqlite_sequence\n",
            "Data mapping completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Connect to SQLite Database and Read Data\n",
        "conn = sqlite3.connect('database/segmented_objects.db')\n",
        "\n",
        "# List all tables in the database\n",
        "tables = pd.read_sql_query(\"SELECT name FROM sqlite_master WHERE type='table';\", conn)\n",
        "print(\"Tables in the database:\", tables)\n",
        "\n",
        "# Read data from the correct table 'objects'\n",
        "object_metadata = pd.read_sql_query(\"SELECT object_id, master_id, image_path FROM objects\", conn)\n",
        "\n",
        "# Close the connection\n",
        "conn.close()\n",
        "\n",
        "# Step 2: Load Other CSV Files\n",
        "descriptions = pd.read_csv('object_descriptions.csv', encoding='latin1')\n",
        "extracted_text = pd.read_csv('extracted_text_data.csv', encoding='latin1')\n",
        "summaries = pd.read_csv('object_summaries.csv', encoding='latin1')\n",
        "\n",
        "# Step 3: Merge DataFrames\n",
        "merged_data = object_metadata.merge(descriptions, on='object_id')\\\n",
        "                             .merge(extracted_text, on='object_id')\\\n",
        "                             .merge(summaries, on='object_id')\n",
        "\n",
        "# Step 4: Create Data Mapping\n",
        "data_mapping = {}\n",
        "\n",
        "for _, row in merged_data.iterrows():\n",
        "    master_id = row['master_id']\n",
        "    object_id = row['object_id']\n",
        "\n",
        "    if master_id not in data_mapping:\n",
        "        data_mapping[master_id] = {\"objects\": []}\n",
        "\n",
        "    object_data = {\n",
        "        \"object_id\": object_id,\n",
        "        \"image_path\": row['image_path'],\n",
        "        \"description\": row['description'],\n",
        "        \"extracted_text\": row['extracted_text'],\n",
        "        \"summary\": row['summary']\n",
        "    }\n",
        "\n",
        "    data_mapping[master_id][\"objects\"].append(object_data)\n",
        "\n",
        "# Save the data mapping to a JSON file\n",
        "with open('data_mapping.json', 'w') as f:\n",
        "    json.dump(data_mapping, f, indent=4)\n",
        "\n",
        "print(\"Data mapping completed successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2G7NrVqxiFvg",
        "outputId": "ca33a626-1f83-4f38-f392-5cfd413fce1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tables in the database:               name\n",
            "0          objects\n",
            "1  sqlite_sequence\n"
          ]
        }
      ],
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# Connect to the SQLite database\n",
        "conn = sqlite3.connect('database/segmented_objects.db')\n",
        "\n",
        "# List all tables in the database\n",
        "tables = pd.read_sql_query(\"SELECT name FROM sqlite_master WHERE type='table';\", conn)\n",
        "print(\"Tables in the database:\", tables)\n",
        "\n",
        "# Read data from the correct table 'objects'\n",
        "object_metadata = pd.read_sql_query(\"SELECT object_id, master_id, image_path FROM objects\", conn)\n",
        "\n",
        "# Close the connection\n",
        "conn.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "2sjS1k47iFyF"
      },
      "outputs": [],
      "source": [
        "# Load other CSV files with correct encoding\n",
        "descriptions = pd.read_csv('object_descriptions.csv', encoding='latin1')\n",
        "extracted_text = pd.read_csv('extracted_text_data.csv', encoding='latin1')\n",
        "summaries = pd.read_csv('object_summaries.csv', encoding='latin1')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-t7yRoliF2H",
        "outputId": "c9cdabc0-86ca-4787-b908-8d47e3b60ff7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data mapping completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Merge all dataframes on object_id\n",
        "merged_data = object_metadata.merge(descriptions, on='object_id')\\\n",
        "                             .merge(extracted_text, on='object_id')\\\n",
        "                             .merge(summaries, on='object_id')\n",
        "\n",
        "# Create a dictionary to hold the data mapping\n",
        "data_mapping = {}\n",
        "\n",
        "for _, row in merged_data.iterrows():\n",
        "    master_id = row['master_id']\n",
        "    object_id = row['object_id']\n",
        "\n",
        "    if master_id not in data_mapping:\n",
        "        data_mapping[master_id] = {\"objects\": []}\n",
        "\n",
        "    object_data = {\n",
        "        \"object_id\": object_id,\n",
        "        \"image_path\": row['image_path'],\n",
        "        \"description\": row['description'],\n",
        "        \"extracted_text\": row['extracted_text'],\n",
        "        \"summary\": row['summary']\n",
        "    }\n",
        "\n",
        "    data_mapping[master_id][\"objects\"].append(object_data)\n",
        "\n",
        "# Save the data mapping to a JSON file\n",
        "with open('data_mapping.json', 'w') as f:\n",
        "    json.dump(data_mapping, f, indent=4)\n",
        "\n",
        "print(\"Data mapping completed successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2K4w7SGjWQE",
        "outputId": "5902a3b0-d757-45d4-e924-81ac4659ef1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (1.37.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.4.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.1)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.1.4)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Requirement already satisfied: watchdog<5,>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.0.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.7.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "pip install streamlit\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNl4mbEUVNYJ",
        "outputId": "1d950dcf-4237-404e-d439-930a1dd65107"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
          ]
        }
      ],
      "source": [
        "import streamlit as st\n",
        "import easyocr\n",
        "from transformers import pipeline  # Example for NLP model\n",
        "import torch\n",
        "from torchvision import models  # Example for image segmentation model\n",
        "\n",
        "\n",
        "# Initialize models (assume functions to load them are defined)\n",
        "reader = easyocr.Reader(['en'])\n",
        "segmentation_model = image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "W9sEwp2ZVTo3",
        "outputId": "e7ba8584-70af-4551-d008-b36f018efd25"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a50f982d-170d-4cf1-bcfb-4f07f161ff5c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a50f982d-170d-4cf1-bcfb-4f07f161ff5c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 2017-bestposter-justiceleague.jpg to 2017-bestposter-justiceleague (2).jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MaskRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=MaskRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Object extraction and storage completed successfully.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sqlite3\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torchvision.transforms as T\n",
        "from google.colab import files\n",
        "import torch\n",
        "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
        "import easyocr\n",
        "from transformers import pipeline\n",
        "\n",
        "# Create directories for saving extracted objects and database\n",
        "os.makedirs('extracted_objects', exist_ok=True)\n",
        "os.makedirs('database', exist_ok=True)\n",
        "\n",
        "# Connect to SQLite database (or create it)\n",
        "conn = sqlite3.connect('database/segmented_objects.db')\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Create table for storing metadata\n",
        "cursor.execute('''\n",
        "CREATE TABLE IF NOT EXISTS objects (\n",
        "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    master_id TEXT,\n",
        "    object_id TEXT,\n",
        "    image_path TEXT\n",
        ")\n",
        "''')\n",
        "\n",
        "# Function to save image with metadata\n",
        "def save_object_image(image, master_id, object_id):\n",
        "    image_path = f'extracted_objects/{object_id}.png'\n",
        "    image.save(image_path)\n",
        "\n",
        "    # Insert metadata into database\n",
        "    cursor.execute('''\n",
        "    INSERT INTO objects (master_id, object_id, image_path)\n",
        "    VALUES (?, ?, ?)\n",
        "    ''', (master_id, object_id, image_path))\n",
        "\n",
        "    conn.commit()\n",
        "\n",
        "# Function to load image from uploaded files\n",
        "def load_image(file_dict):\n",
        "    image = None\n",
        "    for fname in file_dict.keys():\n",
        "        image = Image.open(fname).convert(\"RGB\")\n",
        "    return image\n",
        "\n",
        "# Upload image\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Load image\n",
        "image = load_image(uploaded)\n",
        "\n",
        "# Transform the image for the model\n",
        "transform = T.Compose([\n",
        "    T.ToTensor(),\n",
        "])\n",
        "image_tensor = transform(image)\n",
        "\n",
        "# Load a pre-trained Mask R-CNN model\n",
        "model = maskrcnn_resnet50_fpn(pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "# Run the model on the image\n",
        "with torch.no_grad():\n",
        "    predictions = model([image_tensor])\n",
        "\n",
        "# Get the masks and labels\n",
        "masks = predictions[0]['masks']\n",
        "scores = predictions[0]['scores']\n",
        "\n",
        "# Generate unique master ID for the original image\n",
        "master_id = 'master_' + str(np.random.randint(10000))\n",
        "\n",
        "# Extract and save objects\n",
        "for i in range(len(masks)):\n",
        "    if scores[i] > 0.5:  # Only save confident predictions\n",
        "        mask = masks[i, 0].numpy()\n",
        "        obj_image = Image.fromarray((mask * 255).astype(np.uint8))\n",
        "        obj_image = Image.composite(image, Image.new(\"RGB\", image.size), obj_image)\n",
        "\n",
        "        # Generate unique object ID\n",
        "        object_id = master_id + '_obj_' + str(i)\n",
        "\n",
        "        # Save object image and metadata\n",
        "        save_object_image(obj_image, master_id, object_id)\n",
        "\n",
        "# Close the database connection\n",
        "conn.close()\n",
        "\n",
        "print(\"Object extraction and storage completed successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxpuxnUMV8jD",
        "outputId": "4c71c9bb-8d0e-4e5a-87b0-32f35b7b6643"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-08-04 14:50:11.523 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n"
          ]
        }
      ],
      "source": [
        "import streamlit as st\n",
        "\n",
        "@st.cache_data\n",
        "def load_data():\n",
        "    # your data loading code\n",
        "    return data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X08BeApTWP-7",
        "outputId": "dfe8a022-8bcf-43ba-dcc5-c155ba5a7b9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-08-04 14:50:11.956 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n"
          ]
        }
      ],
      "source": [
        "import streamlit as st\n",
        "import easyocr\n",
        "from PIL import Image\n",
        "\n",
        "st.title(\"Object Detection and Analysis\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Choose an image...\", type=[\"jpg\", \"png\", \"jpeg\"])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    image = Image.open(uploaded_file)\n",
        "    st.image(image, caption='Uploaded Image.', use_column_width=True)\n",
        "    st.write(\"\")\n",
        "    st.write(\"Processing...\")\n",
        "\n",
        "    # Assume you have already defined a function to process the image and get results\n",
        "    results = process_image(image)\n",
        "\n",
        "    st.write(\"Results:\")\n",
        "    st.write(results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyGlDvcPWe5e",
        "outputId": "8af411c0-91cb-4a56-cbf7-c33efc294b01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.2.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyngrok\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoCaPQojWmAd",
        "outputId": "9b7df72e-2f2d-4d47-c73c-4ac9372fab99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "!ngrok authtoken YOUR_AUTHTOKEN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDs_LAZlW104",
        "outputId": "5fd37a4d-026b-4764-95af-56abb22e54f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (1.37.0)\n",
            "Requirement already satisfied: easyocr in /usr/local/lib/python3.10/dist-packages (1.7.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.1+cu121)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.2.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.4.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.1)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.1.4)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Requirement already satisfied: watchdog<5,>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.0.1)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from easyocr) (4.10.0.84)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.13.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.23.2)\n",
            "Requirement already satisfied: python-bidi in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.6.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from easyocr) (6.0.1)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.0.5)\n",
            "Requirement already satisfied: pyclipper in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.3.0.post5)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.11.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.20)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.7.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2.34.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2024.7.24)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (0.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit easyocr transformers torch torchvision pyngrok\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "sgtMdbOSW9os"
      },
      "outputs": [],
      "source": [
        "import streamlit as st\n",
        "import easyocr\n",
        "from PIL import Image\n",
        "from pyngrok import ngrok\n",
        "import subprocess\n",
        "import torch\n",
        "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
        "\n",
        "st.title(\"Object Detection and Analysis\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Choose an image...\", type=[\"jpg\", \"png\", \"jpeg\"])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    image = Image.open(uploaded_file)\n",
        "    st.image(image, caption='Uploaded Image.', use_column_width=True)\n",
        "    st.write(\"\")\n",
        "    st.write(\"Processing...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "aQudG9vqYH5f"
      },
      "outputs": [],
      "source": [
        "# Function to process the image and get results (dummy example)\n",
        "def process_image(image):\n",
        " return \"Sample results\"\n",
        "results = process_image(image)\n",
        "st.write(\"Results:\")\n",
        "st.write(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "Bi4T7kklYO3B"
      },
      "outputs": [],
      "source": [
        "import streamlit as st\n",
        "import easyocr\n",
        "from PIL import Image\n",
        "from pyngrok import ngrok\n",
        "import subprocess\n",
        "import torch\n",
        "from torchvision import transforms as T\n",
        "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
        "from transformers import pipeline\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huIXSvq9YndH",
        "outputId": "62c73b1b-27c6-43bc-c73f-bcc1eb2d9f7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        }
      ],
      "source": [
        "detection_model = maskrcnn_resnet50_fpn(pretrained=True)\n",
        "detection_model.eval()\n",
        "summarizer = pipeline(\"summarization\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlOY9E-jZOrU",
        "outputId": "417952d8-68c4-448f-e741-bbadd526207c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
          ]
        }
      ],
      "source": [
        "reader = easyocr.Reader(['en'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "i9qorgviZUSa"
      },
      "outputs": [],
      "source": [
        "def detect_objects(image):\n",
        "    transform = T.Compose([T.ToTensor()])\n",
        "    image_tensor = transform(image).unsqueeze(0)\n",
        "    with torch.no_grad():\n",
        "        outputs = detection_model(image_tensor)\n",
        "    return outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "at-6fVaNZWG-"
      },
      "outputs": [],
      "source": [
        "def extract_text(image):\n",
        "    results = reader.readtext(np.array(image))\n",
        "    text = \" \".join([res[1] for res in results])\n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "Qh6V7ZhUZYlR"
      },
      "outputs": [],
      "source": [
        "def summarize_text(text):\n",
        "    summary = summarizer(text, max_length=50, min_length=25, do_sample=False)\n",
        "    return summary[0]['summary_text']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "lX3k-G9uZaZY"
      },
      "outputs": [],
      "source": [
        "st.title(\"Object Detection and Analysis\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Choose an image...\", type=[\"jpg\", \"png\", \"jpeg\"])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    image = Image.open(uploaded_file).convert(\"RGB\")\n",
        "    st.image(image, caption='Uploaded Image.', use_column_width=True)\n",
        "    st.write(\"\")\n",
        "    st.write(\"Processing...\")\n",
        "\n",
        "    # Object detection\n",
        "    detection_results = detect_objects(image)\n",
        "    boxes = detection_results[0]['boxes'].data.numpy()\n",
        "    labels = detection_results[0]['labels'].data.numpy()\n",
        "    scores = detection_results[0]['scores'].data.numpy()\n",
        "\n",
        "    # Extract text and summarize for each detected object\n",
        "    objects_data = []\n",
        "    for i, box in enumerate(boxes):\n",
        "        if scores[i] > 0.5:  # Confidence threshold\n",
        "            obj_image = image.crop((box[0], box[1], box[2], box[3]))\n",
        "            text = extract_text(obj_image)\n",
        "            summary = summarize_text(text)\n",
        "            objects_data.append({\n",
        "                'label': labels[i],\n",
        "                'text': text,\n",
        "                'summary': summary\n",
        "            })\n",
        "\n",
        "    st.write(\"Results:\")\n",
        "    for obj_data in objects_data:\n",
        "        st.write(f\"Label: {obj_data['label']}\")\n",
        "        st.write(f\"Extracted Text: {obj_data['text']}\")\n",
        "        st.write(f\"Summary: {obj_data['summary']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPDl5cWma958",
        "outputId": "a84f2bf7-be04-4078-9140-abf9bc3ec271"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "!ngrok authtoken 2k8oU7P1jQWl9MwExUjvkDsuvsS_6PSHjqt2oJy7VjDsFdXnz\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzjEb2zkb8zf",
        "outputId": "47049e11-f2dc-47b2-975d-5bcf230183ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "WARNING:easyocr.easyocr:Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit app is live at: NgrokTunnel: \"https://85f9-34-16-227-172.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ],
      "source": [
        "import streamlit as st\n",
        "import easyocr\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from pyngrok import ngrok\n",
        "import subprocess\n",
        "import torch\n",
        "from torchvision import transforms as T\n",
        "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load models\n",
        "detection_model = maskrcnn_resnet50_fpn(pretrained=True)\n",
        "detection_model.eval()\n",
        "summarizer = pipeline(\"summarization\")\n",
        "\n",
        "# Initialize EasyOCR reader\n",
        "reader = easyocr.Reader(['en'])\n",
        "\n",
        "# Define function for object detection\n",
        "def detect_objects(image):\n",
        "    transform = T.Compose([T.ToTensor()])\n",
        "    image_tensor = transform(image).unsqueeze(0)\n",
        "    with torch.no_grad():\n",
        "        outputs = detection_model(image_tensor)\n",
        "    return outputs\n",
        "\n",
        "# Define function for text extraction\n",
        "def extract_text(image):\n",
        "    results = reader.readtext(np.array(image))\n",
        "    text = \" \".join([res[1] for res in results])\n",
        "    return text\n",
        "\n",
        "# Define function for summarization\n",
        "def summarize_text(text):\n",
        "    summary = summarizer(text, max_length=50, min_length=25, do_sample=False)\n",
        "    return summary[0]['summary_text']\n",
        "\n",
        "st.title(\"Object Detection and Analysis\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Choose an image...\", type=[\"jpg\", \"png\", \"jpeg\"])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    image = Image.open(uploaded_file).convert(\"RGB\")\n",
        "    st.image(image, caption='Uploaded Image.', use_column_width=True)\n",
        "    st.write(\"\")\n",
        "    st.write(\"Processing...\")\n",
        "\n",
        "    # Object detection\n",
        "    detection_results = detect_objects(image)\n",
        "    boxes = detection_results[0]['boxes'].data.numpy()\n",
        "    labels = detection_results[0]['labels'].data.numpy()\n",
        "    scores = detection_results[0]['scores'].data.numpy()\n",
        "\n",
        "    # Extract text and summarize for each detected object\n",
        "    objects_data = []\n",
        "    for i, box in enumerate(boxes):\n",
        "        if scores[i] > 0.5:  # Confidence threshold\n",
        "            obj_image = image.crop((box[0], box[1], box[2], box[3]))\n",
        "            text = extract_text(obj_image)\n",
        "            summary = summarize_text(text)\n",
        "            objects_data.append({\n",
        "                'label': labels[i],\n",
        "                'text': text,\n",
        "                'summary': summary\n",
        "            })\n",
        "\n",
        "    st.write(\"Results:\")\n",
        "    for obj_data in objects_data:\n",
        "        st.write(f\"Label: {obj_data['label']}\")\n",
        "        st.write(f\"Extracted Text: {obj_data['text']}\")\n",
        "        st.write(f\"Summary: {obj_data['summary']}\")\n",
        "\n",
        "# Save the Streamlit script\n",
        "with open('app.py', 'w') as f:\n",
        "    f.write(\"\"\"\n",
        "import streamlit as st\n",
        "import easyocr\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import transforms as T\n",
        "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load models\n",
        "detection_model = maskrcnn_resnet50_fpn(pretrained=True)\n",
        "detection_model.eval()\n",
        "summarizer = pipeline(\"summarization\")\n",
        "\n",
        "# Initialize EasyOCR reader\n",
        "reader = easyocr.Reader(['en'])\n",
        "\n",
        "# Define function for object detection\n",
        "def detect_objects(image):\n",
        "    transform = T.Compose([T.ToTensor()])\n",
        "    image_tensor = transform(image).unsqueeze(0)\n",
        "    with torch.no_grad():\n",
        "        outputs = detection_model(image_tensor)\n",
        "    return outputs\n",
        "\n",
        "# Define function for text extraction\n",
        "def extract_text(image):\n",
        "    results = reader.readtext(np.array(image))\n",
        "    text = \" \".join([res[1] for res in results])\n",
        "    return text\n",
        "\n",
        "# Define function for summarization\n",
        "def summarize_text(text):\n",
        "    summary = summarizer(text, max_length=50, min_length=25, do_sample=False)\n",
        "    return summary[0]['summary_text']\n",
        "\n",
        "st.title(\"Object Detection and Analysis\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Choose an image...\", type=[\"jpg\", \"png\", \"jpeg\"])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    image = Image.open(uploaded_file).convert(\"RGB\")\n",
        "    st.image(image, caption='Uploaded Image.', use_column_width=True)\n",
        "    st.write(\"\")\n",
        "    st.write(\"Processing...\")\n",
        "\n",
        "    # Object detection\n",
        "    detection_results = detect_objects(image)\n",
        "    boxes = detection_results[0]['boxes'].data.numpy()\n",
        "    labels = detection_results[0]['labels'].data.numpy()\n",
        "    scores = detection_results[0]['scores'].data.numpy()\n",
        "\n",
        "    # Extract text and summarize for each detected object\n",
        "    objects_data = []\n",
        "    for i, box in enumerate(boxes):\n",
        "        if scores[i] > 0.5:  # Confidence threshold\n",
        "            obj_image = image.crop((box[0], box[1], box[2], box[3]))\n",
        "            text = extract_text(obj_image)\n",
        "            summary = summarize_text(text)\n",
        "            objects_data.append({\n",
        "                'label': labels[i],\n",
        "                'text': text,\n",
        "                'summary': summary\n",
        "            })\n",
        "\n",
        "    st.write(\"Results:\")\n",
        "    for obj_data in objects_data:\n",
        "        st.write(f\"Label: {obj_data['label']}\")\n",
        "        st.write(f\"Extracted Text: {obj_data['text']}\")\n",
        "        st.write(f\"Summary: {obj_data['summary']}\")\n",
        "    \"\"\")\n",
        "\n",
        "# Run the Streamlit app with Ngrok\n",
        "command = \"streamlit run app.py\"\n",
        "process = subprocess.Popen(command, shell=True)\n",
        "url = ngrok.connect(8501)\n",
        "print(f\"Streamlit app is live at: {url}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykUNEY4-frFR"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "yI5f2n38f-4y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "130a2cb9-1c56-486d-c3ee-8ffeac66b9a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "U5u0PIgjrl44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d89ed500-e8f6-4bfa-ee73-1d91aa7b86f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "WARNING:easyocr.easyocr:Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
          ]
        }
      ],
      "source": [
        "import streamlit as st\n",
        "import easyocr\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import transforms as T\n",
        "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
        "from transformers import pipeline\n",
        "import pandas as pd\n",
        "\n",
        "# Load models\n",
        "detection_model = maskrcnn_resnet50_fpn(pretrained=True)\n",
        "detection_model.eval()\n",
        "summarizer = pipeline(\"summarization\")\n",
        "\n",
        "# Initialize EasyOCR reader\n",
        "reader = easyocr.Reader(['en'])\n",
        "\n",
        "# Define function for object detection\n",
        "def detect_objects(image):\n",
        "    transform = T.Compose([T.ToTensor()])\n",
        "    image_tensor = transform(image).unsqueeze(0)\n",
        "    with torch.no_grad():\n",
        "        outputs = detection_model(image_tensor)\n",
        "    return outputs\n",
        "\n",
        "# Define function for text extraction\n",
        "def extract_text(image):\n",
        "    results = reader.readtext(np.array(image))\n",
        "    text = \" \".join([res[1] for res in results])\n",
        "    return text\n",
        "\n",
        "# Define function for summarization\n",
        "def summarize_text(text):\n",
        "    summary = summarizer(text, max_length=50, min_length=25, do_sample=False)\n",
        "    return summary[0]['summary_text']\n",
        "\n",
        "st.title(\"Object Detection and Analysis\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Choose an image...\", type=[\"jpg\", \"png\", \"jpeg\"])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    image = Image.open(uploaded_file).convert(\"RGB\")\n",
        "    st.image(image, caption='Uploaded Image.', use_column_width=True)\n",
        "    st.write(\"\")\n",
        "    st.write(\"Processing...\")\n",
        "\n",
        "    # Object detection\n",
        "    detection_results = detect_objects(image)\n",
        "    boxes = detection_results[0]['boxes'].data.numpy()\n",
        "    labels = detection_results[0]['labels'].data.numpy()\n",
        "    scores = detection_results[0]['scores'].data.numpy()\n",
        "\n",
        "    # Prepare data for summary table\n",
        "    objects_data = []\n",
        "    for i, box in enumerate(boxes):\n",
        "        if scores[i] > 0.5:  # Confidence threshold\n",
        "            obj_image = image.crop((box[0], box[1], box[2], box[3]))\n",
        "            text = extract_text(obj_image)\n",
        "            summary = summarize_text(text)\n",
        "            objects_data.append({\n",
        "                'Object ID': i,\n",
        "                'Class Label': labels[i],\n",
        "                'Confidence Score': scores[i],\n",
        "                'Bounding Box Coordinates': box,\n",
        "                'Extracted Text': text,\n",
        "                'Summary': summary\n",
        "            })\n",
        "\n",
        "    # Create a DataFrame for the summary table\n",
        "    df = pd.DataFrame(objects_data)\n",
        "\n",
        "    st.write(\"Results:\")\n",
        "    st.table(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import easyocr\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import transforms as T\n",
        "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
        "from transformers import pipeline\n",
        "import pandas as pd\n",
        "from pyngrok import ngrok\n",
        "import subprocess\n",
        "\n",
        "# Load models\n",
        "detection_model = maskrcnn_resnet50_fpn(pretrained=True)\n",
        "detection_model.eval()\n",
        "summarizer = pipeline(\"summarization\")\n",
        "\n",
        "# Initialize EasyOCR reader\n",
        "reader = easyocr.Reader(['en'])\n",
        "\n",
        "# Define function for object detection\n",
        "def detect_objects(image):\n",
        "    transform = T.Compose([T.ToTensor()])\n",
        "    image_tensor = transform(image).unsqueeze(0)\n",
        "    with torch.no_grad():\n",
        "        outputs = detection_model(image_tensor)\n",
        "    return outputs\n",
        "\n",
        "# Define function for text extraction\n",
        "def extract_text(image):\n",
        "    results = reader.readtext(np.array(image))\n",
        "    text = \" \".join([res[1] for res in results])\n",
        "    return text\n",
        "\n",
        "# Define function for summarization\n",
        "def summarize_text(text):\n",
        "    summary = summarizer(text, max_length=50, min_length=25, do_sample=False)\n",
        "    return summary[0]['summary_text']\n",
        "\n",
        "st.title(\"Object Detection and Analysis\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Choose an image...\", type=[\"jpg\", \"png\", \"jpeg\"])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    image = Image.open(uploaded_file).convert(\"RGB\")\n",
        "    st.image(image, caption='Uploaded Image.', use_column_width=True)\n",
        "    st.write(\"\")\n",
        "    st.write(\"Processing...\")\n",
        "\n",
        "    # Object detection\n",
        "    detection_results = detect_objects(image)\n",
        "    boxes = detection_results[0]['boxes'].data.numpy()\n",
        "    labels = detection_results[0]['labels'].data.numpy()\n",
        "    scores = detection_results[0]['scores'].data.numpy()\n",
        "\n",
        "    # Prepare data for summary table\n",
        "    objects_data = []\n",
        "    for i, box in enumerate(boxes):\n",
        "        if scores[i] > 0.5:  # Confidence threshold\n",
        "            obj_image = image.crop((box[0], box[1], box[2], box[3]))\n",
        "            text = extract_text(obj_image)\n",
        "            summary = summarize_text(text)\n",
        "            objects_data.append({\n",
        "                'Object ID': i,\n",
        "                'Class Label': labels[i],\n",
        "                'Confidence Score': scores[i],\n",
        "                'Bounding Box Coordinates': box,\n",
        "                'Extracted Text': text,\n",
        "                'Summary': summary\n",
        "            })\n",
        "\n",
        "    # Create a DataFrame for the summary table\n",
        "    df = pd.DataFrame(objects_data)\n",
        "\n",
        "    st.write(\"Results:\")\n",
        "    st.table(df)\n",
        "\n",
        "# Save the Streamlit script\n",
        "with open('app.py', 'w') as f:\n",
        "    f.write(\"\"\"\n",
        "import streamlit as st\n",
        "import easyocr\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import transforms as T\n",
        "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
        "from transformers import pipeline\n",
        "import pandas as pd\n",
        "\n",
        "# Load models\n",
        "detection_model = maskrcnn_resnet50_fpn(pretrained=True)\n",
        "detection_model.eval()\n",
        "summarizer = pipeline(\"summarization\")\n",
        "\n",
        "# Initialize EasyOCR reader\n",
        "reader = easyocr.Reader(['en'])\n",
        "\n",
        "# Define function for object detection\n",
        "def detect_objects(image):\n",
        "    transform = T.Compose([T.ToTensor()])\n",
        "    image_tensor = transform(image).unsqueeze(0)\n",
        "    with torch.no_grad():\n",
        "        outputs = detection_model(image_tensor)\n",
        "    return outputs\n",
        "\n",
        "# Define function for text extraction\n",
        "def extract_text(image):\n",
        "    results = reader.readtext(np.array(image))\n",
        "    text = \" \".join([res[1] for res in results])\n",
        "    return text\n",
        "\n",
        "# Define function for summarization\n",
        "def summarize_text(text):\n",
        "    summary = summarizer(text, max_length=50, min_length=25, do_sample=False)\n",
        "    return summary[0]['summary_text']\n",
        "\n",
        "st.title(\"Object Detection and Analysis\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Choose an image...\", type=[\"jpg\", \"png\", \"jpeg\"])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    image = Image.open(uploaded_file).convert(\"RGB\")\n",
        "    st.image(image, caption='Uploaded Image.', use_column_width=True)\n",
        "    st.write(\"\")\n",
        "    st.write(\"Processing...\")\n",
        "\n",
        "    # Object detection\n",
        "    detection_results = detect_objects(image)\n",
        "    boxes = detection_results[0]['boxes'].data.numpy()\n",
        "    labels = detection_results[0]['labels'].data.numpy()\n",
        "    scores = detection_results[0]['scores'].data.numpy()\n",
        "\n",
        "    # Prepare data for summary table\n",
        "    objects_data = []\n",
        "    for i, box in enumerate(boxes):\n",
        "        if scores[i] > 0.5:  # Confidence threshold\n",
        "            obj_image = image.crop((box[0], box[1], box[2], box[3]))\n",
        "            text = extract_text(obj_image)\n",
        "            summary = summarize_text(text)\n",
        "            objects_data.append({\n",
        "                'Object ID': i,\n",
        "                'Class Label': labels[i],\n",
        "                'Confidence Score': scores[i],\n",
        "                'Bounding Box Coordinates': box,\n",
        "                'Extracted Text': text,\n",
        "                'Summary': summary\n",
        "            })\n",
        "\n",
        "    # Create a DataFrame for the summary table\n",
        "    df = pd.DataFrame(objects_data)\n",
        "\n",
        "    st.write(\"Results:\")\n",
        "    st.table(df)\n",
        "    \"\"\")\n",
        "\n",
        "# Run the Streamlit app with Ngrok\n",
        "command = \"streamlit run app.py\"\n",
        "process = subprocess.Popen(command, shell=True)\n",
        "url = ngrok.connect(8501)\n",
        "print(f\"Streamlit app is live at: {url}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHT_9DYn34Ll",
        "outputId": "b0f3989b-5bc0-4548-ad33-15943f4676c2"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "WARNING:easyocr.easyocr:Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit app is live at: NgrokTunnel: \"https://5c20-34-16-227-172.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "F9ckRyRfIj_2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TjEBcseK34O3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kk-tFp3k34SJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ysN0_1Go34VO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JwdSfPmp34YL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6P3j2OhS34bV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RwsLEJun34en"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "40306821b3414eee8bfb950b03c2d6ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_02fc0812dd4e4b1fa4d977b76079c97c",
              "IPY_MODEL_1b5d787727f54f92ade54bc0f7c5a279",
              "IPY_MODEL_3716eac980884ce1b64ceec691da2079"
            ],
            "layout": "IPY_MODEL_bd7888ce12a84b23ab443cd9918e7ae5"
          }
        },
        "02fc0812dd4e4b1fa4d977b76079c97c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_962e5f68759f46f087aefe7c7d60a2c0",
            "placeholder": "​",
            "style": "IPY_MODEL_b90940076bc246a2bb7aff1ef51daac2",
            "value": "config.json: 100%"
          }
        },
        "1b5d787727f54f92ade54bc0f7c5a279": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c266010897b546a79a36c621723bcd06",
            "max": 1802,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_22d84ffd7ebf49f0917facc980597701",
            "value": 1802
          }
        },
        "3716eac980884ce1b64ceec691da2079": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5e3a0f34ed8444ea6090f8edc4db27c",
            "placeholder": "​",
            "style": "IPY_MODEL_d746c3cb6f3a4bec8fdf2c5cc23e867f",
            "value": " 1.80k/1.80k [00:00&lt;00:00, 91.7kB/s]"
          }
        },
        "bd7888ce12a84b23ab443cd9918e7ae5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "962e5f68759f46f087aefe7c7d60a2c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b90940076bc246a2bb7aff1ef51daac2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c266010897b546a79a36c621723bcd06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22d84ffd7ebf49f0917facc980597701": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a5e3a0f34ed8444ea6090f8edc4db27c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d746c3cb6f3a4bec8fdf2c5cc23e867f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b59d32a6d944b529185cbc5c23ea04d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f3c2941dff174eb686f036d54c89439f",
              "IPY_MODEL_6e6620330e4642b68865dce0e9d874a8",
              "IPY_MODEL_56ecc7a239d64f1aa3dc4dceb52be534"
            ],
            "layout": "IPY_MODEL_9e4a1a1b795c43018910cf201f80c3f3"
          }
        },
        "f3c2941dff174eb686f036d54c89439f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed8e66fa611f4c16b794bcdb8c32cdca",
            "placeholder": "​",
            "style": "IPY_MODEL_bbbb1c78f1014c28b137eaff8f4befa8",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "6e6620330e4642b68865dce0e9d874a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e45957ddd574bdd80cb7566361e4b67",
            "max": 1222317369,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1650945944734f7cbccd76794101ca76",
            "value": 1222317369
          }
        },
        "56ecc7a239d64f1aa3dc4dceb52be534": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_506906f469404aecb938de914a078bc9",
            "placeholder": "​",
            "style": "IPY_MODEL_cbec80d1d097437184022d5051cb751c",
            "value": " 1.22G/1.22G [00:16&lt;00:00, 109MB/s]"
          }
        },
        "9e4a1a1b795c43018910cf201f80c3f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed8e66fa611f4c16b794bcdb8c32cdca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbbb1c78f1014c28b137eaff8f4befa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e45957ddd574bdd80cb7566361e4b67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1650945944734f7cbccd76794101ca76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "506906f469404aecb938de914a078bc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbec80d1d097437184022d5051cb751c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "595e933dc6b04b05ab3e77cfde2f2595": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_486444665624443b9f04778a3b450aa0",
              "IPY_MODEL_a5b36dd8326e46b89f0ba101cdc6d201",
              "IPY_MODEL_8fc30719b070432e8733de0f027feec6"
            ],
            "layout": "IPY_MODEL_bf30c92a572a4a049985f57663db3406"
          }
        },
        "486444665624443b9f04778a3b450aa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e94353f5e1ca4e82ab56f6e72f963e6d",
            "placeholder": "​",
            "style": "IPY_MODEL_96db8f5cb9124857902d490353ecd72e",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "a5b36dd8326e46b89f0ba101cdc6d201": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be3562e80cdd45d9bb99ebd9de637c31",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_07e91e791af74b68b113e9ec90ad5b02",
            "value": 26
          }
        },
        "8fc30719b070432e8733de0f027feec6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95d96240bf044a7b9d93bbd8d57f27fd",
            "placeholder": "​",
            "style": "IPY_MODEL_4dbeb5c8f9c34237983aa10cd8c28488",
            "value": " 26.0/26.0 [00:00&lt;00:00, 360B/s]"
          }
        },
        "bf30c92a572a4a049985f57663db3406": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e94353f5e1ca4e82ab56f6e72f963e6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96db8f5cb9124857902d490353ecd72e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be3562e80cdd45d9bb99ebd9de637c31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07e91e791af74b68b113e9ec90ad5b02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "95d96240bf044a7b9d93bbd8d57f27fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4dbeb5c8f9c34237983aa10cd8c28488": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a176519cc891486f8bc57002e1cdbba0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6381bafb1179423fadc755a409bdb34c",
              "IPY_MODEL_879bb8035884482a942866c90d58d150",
              "IPY_MODEL_51db171daf3f434bb1da11324d5a7f93"
            ],
            "layout": "IPY_MODEL_18aa878ef256402daaf4f35bf25e849e"
          }
        },
        "6381bafb1179423fadc755a409bdb34c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7dc5cd7a8d14596b2407292bf4b131b",
            "placeholder": "​",
            "style": "IPY_MODEL_89ef9d0c34ed4e00a9cd7ea02be14243",
            "value": "vocab.json: 100%"
          }
        },
        "879bb8035884482a942866c90d58d150": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0123f24b86d24941a061aa0f299e750a",
            "max": 898822,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_79f24422b0c841eabe60611d84dd1112",
            "value": 898822
          }
        },
        "51db171daf3f434bb1da11324d5a7f93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cb7f1d7274642268a94fd0b799f935e",
            "placeholder": "​",
            "style": "IPY_MODEL_50d04fdb8d5c4e23aa6e64d43c175423",
            "value": " 899k/899k [00:00&lt;00:00, 5.83MB/s]"
          }
        },
        "18aa878ef256402daaf4f35bf25e849e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7dc5cd7a8d14596b2407292bf4b131b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89ef9d0c34ed4e00a9cd7ea02be14243": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0123f24b86d24941a061aa0f299e750a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79f24422b0c841eabe60611d84dd1112": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4cb7f1d7274642268a94fd0b799f935e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50d04fdb8d5c4e23aa6e64d43c175423": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1017c5f275754070b7cb91491c9d30e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_01e62dd02ea24019a5a59fbce06f5c5e",
              "IPY_MODEL_8c5e3e77484b48f580950e2d07921db4",
              "IPY_MODEL_6de8565f0a054414847fb03e55d8906f"
            ],
            "layout": "IPY_MODEL_d1a2059c4a714d2daa4eee49504accac"
          }
        },
        "01e62dd02ea24019a5a59fbce06f5c5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec85e00e920a4211ab1cf31bfcf738e1",
            "placeholder": "​",
            "style": "IPY_MODEL_9adedadc98b04694a2e6a7c8349cae1f",
            "value": "merges.txt: 100%"
          }
        },
        "8c5e3e77484b48f580950e2d07921db4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e34f2a5923f4cb78a5d92e258033582",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_56acb744ee6640af80fb13f0d682e113",
            "value": 456318
          }
        },
        "6de8565f0a054414847fb03e55d8906f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_599cdde41af74cfdb4cef4eb483a6daf",
            "placeholder": "​",
            "style": "IPY_MODEL_8702b18e9a214257b6eb233e470326c7",
            "value": " 456k/456k [00:00&lt;00:00, 3.21MB/s]"
          }
        },
        "d1a2059c4a714d2daa4eee49504accac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec85e00e920a4211ab1cf31bfcf738e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9adedadc98b04694a2e6a7c8349cae1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e34f2a5923f4cb78a5d92e258033582": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56acb744ee6640af80fb13f0d682e113": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "599cdde41af74cfdb4cef4eb483a6daf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8702b18e9a214257b6eb233e470326c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}